{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d0d2ab-838c-4816-80e9-07a0ab41bf07",
   "metadata": {},
   "source": [
    "# üìä Preparing Tableau Dashboards for Credit Risk Insights\n",
    "\n",
    "In this final notebook, I prepare targeted CSV files from our validation dataset and SHAP outputs to support **interactive Tableau dashboards**. These dashboards are designed to communicate key insights from the credit risk modeling pipeline to both technical and non-technical audiences.\n",
    "\n",
    "### üéØ Objectives\n",
    "\n",
    "- Export curated datasets to power five core Tableau visualizations:\n",
    "  - üîç SHAP Global Importance  \n",
    "    Summary of the top features influencing model predictions.\n",
    "  - üéØ Score by Actual Outcome  \n",
    "    Distribution of predicted probabilities grouped by ground truth.\n",
    "  - üß† SHAP by Risk Group  \n",
    "    Aggregated SHAP values segmented by low, medium, and high-risk bands.\n",
    "  - üìà Feature Impact on Score  \n",
    "    Visualizes how selected features influence loan default probability.\n",
    "  - ‚úèÔ∏è Confusion Matrix & Metrics  \n",
    "    Includes precision, recall, and classification breakdown.\n",
    "\n",
    "Each export is tailored to maximize clarity, interactivity, and storytelling impact inside Tableau Public.\n",
    "\n",
    "> This notebook acts as the **bridge between machine learning outputs and stakeholder communication**, enabling the delivery of interpretable, transparent credit risk insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc152078-b47f-4296-a015-84739827df46",
   "metadata": {},
   "source": [
    "---\n",
    "### üì¶ Load Required Libraries\n",
    "\n",
    "I begin by importing the essential libraries for this final notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766d9fb6-c901-4666-aaa1-2008ec912ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Model loading and evaluation tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# SHAP explanations and LightGBM model compatibility\n",
    "import shap\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Suppress SHAP warning about binary classifiers\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1322f8ce-1b42-43c7-84ae-10654a8ae804",
   "metadata": {},
   "source": [
    "### üß† Load Trained Model and Validation Data\n",
    "\n",
    "I begin by loading the final trained LightGBM model along with the validation dataset and corresponding labels. These will be used to generate prediction outputs and SHAP values for Tableau-ready visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7261ade6-0e85-4703-a095-8a4da11aeabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the final trained LightGBM model\n",
    "model = joblib.load(\"../models/lgbm_model.joblib\")\n",
    "\n",
    "# Load the validation feature set\n",
    "X_valid = pd.read_parquet(\"../data/processed/X_valid.parquet\")\n",
    "\n",
    "# Load the corresponding validation labels\n",
    "y_valid = pd.read_parquet(\"../data/processed/y_valid.parquet\").squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f52869-2bee-48e7-8303-4eb0ce39d5e2",
   "metadata": {},
   "source": [
    "### üìä Prepare Global SHAP Summary for Tableau Dashboarding\n",
    "\n",
    "In this section, I generate a summary of global feature importance using SHAP values and prepare it for visualization in Tableau.\n",
    "\n",
    "- First, I predict loan default probabilities on the validation set and assign class labels based on the chosen threshold (0.3).\n",
    "- I then compute **SHAP values** using `TreeExplainer`, which is optimized for our LightGBM model.\n",
    "- To summarize global importance, I calculate the **mean absolute SHAP value per feature**, giving us a ranked list of the most influential variables.\n",
    "- Finally, I save this summary to a CSV file (`global_shap_importance.csv`) in the `data/final/` directory. This file can be easily loaded into Tableau to build an interactive feature importance dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f8e91ce-021d-4444-8668-0cc6e94db619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Global SHAP feature importance saved to global_shap_importance.csv\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities and assign predicted labels using chosen threshold\n",
    "y_pred_proba = model.predict_proba(X_valid)[:, 1]\n",
    "# Apply threshold of 0.3 to convert probabilities into class labels\n",
    "y_pred_thresh = (y_pred_proba >= 0.3).astype(int)\n",
    "\n",
    "# Add prediction columns to X_valid\n",
    "X_valid_final = X_valid.copy()\n",
    "X_valid_final[\"loan_default_proba\"] = y_pred_proba\n",
    "X_valid_final[\"predicted_label\"] = y_pred_thresh\n",
    "X_valid_final[\"actual_label\"] = y_valid.values\n",
    "\n",
    "# Initialize SHAP explainer (TreeExplainer for LightGBM)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Compute SHAP values (shape: [n_samples, n_features])\n",
    "shap_values = explainer.shap_values(X_valid)\n",
    "\n",
    "# Compute global SHAP feature importance (mean absolute value)\n",
    "global_importance = (\n",
    "    pd.DataFrame(shap_values, columns=X_valid.columns)\n",
    "    .abs()\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"feature_name\", 0: \"mean_abs_shap_value\"})\n",
    "    .sort_values(\"mean_abs_shap_value\", ascending=False)\n",
    ")\n",
    "\n",
    "# Save global SHAP importance summary for Tableau\n",
    "global_importance.to_csv(\"../data/final/global_shap_importance.csv\", index=False)\n",
    "print(\"‚úÖ Global SHAP feature importance saved to global_shap_importance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e75ed-a5d2-4815-8939-79ec4daf7ad7",
   "metadata": {},
   "source": [
    "### üìä Save Risk Distribution Data for Tableau\n",
    "\n",
    "To support visual analysis of loan default risk scores in Tableau, I prepare a dataset containing key applicant features and the model‚Äôs predicted probabilities:\n",
    "\n",
    "- `loan_default_proba`: Model‚Äôs predicted probability of default\n",
    "- `actual_label`: Ground truth indicating default or not\n",
    "- `label`: Readable label version of the actual class (e.g., ‚ÄúDefault‚Äù, ‚ÄúNo Default‚Äù)\n",
    "\n",
    "This file can be used to create histograms, density plots, or stratified risk profiles in Tableau dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c15b70d1-b765-4197-b677-f2f2b7c386bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Risk distribution saved to risk_distribution.csv\n"
     ]
    }
   ],
   "source": [
    "# Add readable labels to indicate default vs no default\n",
    "X_valid_final[\"label\"] = X_valid_final[\"actual_label\"].map({0: \"No Default\", 1: \"Default\"})\n",
    "\n",
    "# Select relevant columns for visualization\n",
    "risk_df = X_valid_final[[\n",
    "    \"loan_default_proba\",\n",
    "    \"actual_label\",\n",
    "    \"label\"\n",
    "]]\n",
    "\n",
    "# Save to CSV\n",
    "risk_df.to_csv(\"../data/final/risk_distribution.csv\", index=False)\n",
    "print(\"‚úÖ Risk distribution saved to risk_distribution.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74af526-7227-4242-8b5a-5bea37a6a374",
   "metadata": {},
   "source": [
    "### üìä Aggregate SHAP Values by Risk Band for Tableau\n",
    "\n",
    "To enable segmented interpretation of model behavior, I prepare an aggregated SHAP summary grouped by predicted risk bands:\n",
    "\n",
    "- Assign each applicant to a **risk band** based on their predicted probability of default:\n",
    "  - Low Risk: 0.0‚Äì0.2\n",
    "  - Medium Risk: 0.2‚Äì0.5\n",
    "  - High Risk: 0.5‚Äì1.0\n",
    "- Compute **mean absolute SHAP values** across all validation samples to identify the top 15 most influential features.\n",
    "- Reshape these SHAP values into long format grouped by risk band, then compute the **average SHAP impact per feature per band**.\n",
    "- Export the result as `agg_shap_by_risk_band.csv`, ready for Tableau heatmaps or bar plots to show which features drive different levels of credit risk.\n",
    "\n",
    "This segmentation reveals **how different applicant profiles are evaluated by the model**, supporting transparent, risk-aware storytelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67e64e1-1dab-4f5b-a798-a8e0bb2b2a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SHAP aggregation saved to agg_shap_by_risk_band.csv\n"
     ]
    }
   ],
   "source": [
    "# Create risk bands from predicted default probabilities\n",
    "bins = [0, 0.2, 0.5, 1.0]\n",
    "labels = [\"Low Risk\", \"Medium Risk\", \"High Risk\"]\n",
    "X_valid_final[\"risk_band\"] = pd.cut(X_valid_final[\"loan_default_proba\"], bins=bins, labels=labels)\n",
    "\n",
    "# Compute top 15 features by mean absolute SHAP value\n",
    "shap_df = pd.DataFrame(shap_values, columns=X_valid.columns)\n",
    "mean_abs_shap = shap_df.abs().mean().sort_values(ascending=False)\n",
    "top_features = mean_abs_shap.head(15).index.tolist()\n",
    "\n",
    "# Add risk band to SHAP values DataFrame\n",
    "shap_df[\"risk_band\"] = X_valid_final[\"risk_band\"]\n",
    "\n",
    "# Melt to long format for Tableau\n",
    "shap_melted = shap_df[[\"risk_band\"] + top_features].melt(\n",
    "    id_vars=\"risk_band\", var_name=\"feature\", value_name=\"shap_value\"\n",
    ")\n",
    "\n",
    "# Aggregate SHAP values by risk band and feature\n",
    "agg_df = shap_melted.groupby([\"risk_band\", \"feature\"], observed=True).mean().reset_index()\n",
    "\n",
    "# Save to CSV for Tableau\n",
    "agg_df.to_csv(\"../data/final/agg_shap_by_risk_band.csv\", index=False)\n",
    "print(\"‚úÖ SHAP aggregation saved to agg_shap_by_risk_band.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c72182-056c-45b6-810b-331aa65c399a",
   "metadata": {},
   "source": [
    "### üìä Prepare SHAP vs. Risk Score Data for Tableau\n",
    "\n",
    "In this section, I generate a **long-format dataset** that connects SHAP feature contributions to the model‚Äôs predicted probability of default.\n",
    "\n",
    "- I select **8 key features** based on their relevance to financial behavior and SHAP impact: external scores, credit ratios, demographics, and employment type.\n",
    "- SHAP values for each selected feature are combined with the model‚Äôs `loan_default_proba` scores.\n",
    "- The data is **reshaped into long format**, with one row per (applicant, feature) pair, suitable for scatterplots or faceted visualizations in Tableau.\n",
    "- This enables detailed analysis of how each feature influences risk scores across the applicant population.\n",
    "\n",
    "The final CSV (`shap_vs_risk_long.csv`) allows stakeholders to explore which features drive default probability at different risk levels, uncovering nuanced patterns and potential biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f79f113-58b1-47ca-a3e5-c9ddd914b3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SHAP vs risk score (long format) saved to shap_vs_risk_long.csv\n"
     ]
    }
   ],
   "source": [
    "# Select key features to analyze SHAP contributions vs. risk probability\n",
    "selected_features = [\n",
    "    \"EXT_SOURCE_1\",\n",
    "    \"EXT_SOURCE_2\",\n",
    "    \"EXT_SOURCE_3\",\n",
    "    \"credit_annuity_ratio\",\n",
    "    \"credit_goods_ratio\",\n",
    "    \"CODE_GENDER_M\",\n",
    "    \"DAYS_BIRTH\",\n",
    "    \"ORGANIZATION_TYPE_TE\"\n",
    "]\n",
    "\n",
    "# Subset SHAP values for selected features\n",
    "shap_selected = pd.DataFrame(shap_values, columns=X_valid.columns)[selected_features]\n",
    "\n",
    "# Combine with predicted probabilities\n",
    "shap_vs_risk_df = shap_selected.copy()\n",
    "shap_vs_risk_df[\"loan_default_proba\"] = y_pred_proba\n",
    "\n",
    "# Melt into long format for Tableau visualization\n",
    "shap_vs_risk_long = shap_vs_risk_df.melt(\n",
    "    id_vars=\"loan_default_proba\",\n",
    "    value_vars=selected_features,\n",
    "    var_name=\"feature\",\n",
    "    value_name=\"shap_value\"\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "shap_vs_risk_long.to_csv(\"../data/final/shap_vs_risk_long.csv\", index=False)\n",
    "print(\"‚úÖ SHAP vs risk score (long format) saved to shap_vs_risk_long.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b9fea2-dd45-4d62-a6d5-90885adb9a7e",
   "metadata": {},
   "source": [
    "### üìä Export Row-Level Confusion Matrix Predictions for Tableau\n",
    "\n",
    "In this step, I prepare a clean, row-level dataset showing each applicant‚Äôs predicted and actual class along with their model-assigned probability of default. This file powers a **confusion matrix visualization** in Tableau that includes:\n",
    "\n",
    "- `loan_default_proba`: Predicted probability of default  \n",
    "- `predicted_label`: Model-assigned class label (0 = No Default, 1 = Default)  \n",
    "- `actual_label`: Ground truth from the validation set  \n",
    "\n",
    "This format is optimized for **flexible Tableau interactivity**, enabling visual breakdowns by true vs false positives/negatives, model confidence, and threshold-based performance tuning.\n",
    "\n",
    "The output is saved as `confusion_prediction_only.csv` in the `data/final/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33306b16-a314-4d58-a6f0-f2914cd131da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: confusion_prediction_only.csv\n"
     ]
    }
   ],
   "source": [
    "# Select only prediction-relevant columns\n",
    "df_pred = X_valid_final[[\"loan_default_proba\", \"predicted_label\", \"actual_label\"]].copy()\n",
    "\n",
    "# Save to final output directory\n",
    "df_pred.to_csv(\"../data/final/confusion_prediction_only.csv\", index=False)\n",
    "print(\"‚úÖ Saved: confusion_prediction_only.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daf9801-cf5a-4e01-91e9-55ce4ff9c84d",
   "metadata": {},
   "source": [
    "### üìä Export Confusion Matrix Summary for Tableau\n",
    "\n",
    "To complement the row-level predictions, I generate a concise **confusion matrix summary** to visualize true/false positives and negatives in Tableau:\n",
    "\n",
    "- Calculates `True Positive`, `False Positive`, `False Negative`, and `True Negative` counts using logical conditions.\n",
    "- Adds placeholder columns (`loan_default_proba`, `actual_label`, `predicted_label`) to maintain schema consistency with the prediction-level export.\n",
    "- Includes a `Source` column to distinguish this summary from row-level predictions when combining both for dashboarding.\n",
    "\n",
    "This file (`confusion_summary.csv`) provides a high-level view of model performance, useful for heatmaps, confusion matrix visuals, or dashboard tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d52c2a1f-3e58-45ef-b617-e2e8de620608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summary saved: confusion_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrix components directly from predicted vs actual labels\n",
    "TP = ((y_valid == 1) & (y_pred_thresh == 1)).sum()\n",
    "TN = ((y_valid == 0) & (y_pred_thresh == 0)).sum()\n",
    "FP = ((y_valid == 0) & (y_pred_thresh == 1)).sum()\n",
    "FN = ((y_valid == 1) & (y_pred_thresh == 0)).sum()\n",
    "\n",
    "# Create a summary DataFrame in Tableau-friendly format\n",
    "confusion_summary = pd.DataFrame({\n",
    "    \"Metric\": [\"True Positive\", \"False Positive\", \"False Negative\", \"True Negative\"],\n",
    "    \"Count\": [TP, FP, FN, TN],\n",
    "    \"loan_default_proba\": [pd.NA] * 4,\n",
    "    \"actual_label\": [pd.NA] * 4,\n",
    "    \"predicted_label\": [pd.NA] * 4,\n",
    "    \"Source\": [\"Summary\"] * 4\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "confusion_summary.to_csv(\"../data/final/confusion_summary.csv\", index=False)\n",
    "print(\"‚úÖ Summary saved: confusion_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f691c0df-27e2-4554-a414-9076178555fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Final Notes\n",
    "\n",
    "All required datasets for Tableau dashboarding have now been successfully exported and saved in the `data/final/` directory:\n",
    "\n",
    "| CSV File                         | Purpose                                |\n",
    "|----------------------------------|----------------------------------------|\n",
    "| global_shap_importance.csv       | SHAP global feature importance         |\n",
    "| risk_distribution.csv            | Predicted risk vs. actual outcome      |\n",
    "| agg_shap_by_risk_band.csv        | SHAP mean by risk group                |\n",
    "| shap_vs_risk_long.csv            | SHAP vs. score (long format)           |\n",
    "| confusion_prediction_only.csv    | Row-level prediction and outcome       |\n",
    "| confusion_summary.csv            | Summary of confusion matrix counts     |\n",
    "\n",
    "These files support a range of visualizations‚Äîfrom feature importance and risk stratification to confusion matrix insights.\n",
    "\n",
    "> This marks the completion of the modeling-to-visualization pipeline. The next stage focuses on building a transparent, interactive credit risk dashboard in **Tableau Public**, translating ML insights into accessible, decision-ready narratives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
