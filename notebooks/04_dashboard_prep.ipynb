{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766d9fb6-c901-4666-aaa1-2008ec912ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Imports (if needed)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import shap\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "250e6e14-0116-4cf4-a0cd-02b840ade9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Load model and data\n",
    "model = joblib.load(\"../models/lgbm_model.joblib\")  # ‚úÖ Your trained LightGBM model\n",
    "X_valid = pd.read_parquet(\"../data/processed/X_valid.parquet\")  # ‚úÖ Your validation features\n",
    "y_valid = pd.read_csv(\"../data/processed/y_valid.csv\").squeeze()  # ‚úÖ Your validation labels\n",
    "\n",
    "# üìä Predict probabilities and assign predicted labels using chosen threshold\n",
    "y_pred_proba = model.predict_proba(X_valid)[:, 1]\n",
    "y_pred_thresh = (y_pred_proba >= 0.3).astype(int)\n",
    "\n",
    "# üßÆ Add predictions to a copy of X_valid\n",
    "X_valid_final = X_valid.copy()\n",
    "X_valid_final[\"loan_default_proba\"] = y_pred_proba\n",
    "X_valid_final[\"predicted_label\"] = y_pred_thresh\n",
    "X_valid_final[\"actual_label\"] = y_valid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8657e177-fa60-4ae4-874d-433b9d3da6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP shape: (61503, 92)\n",
      "‚úÖ SHAP values saved!\n"
     ]
    }
   ],
   "source": [
    "# üìà Initialize SHAP explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# ‚ö†Ô∏è Suppress SHAP warning about binary classifiers (optional)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ‚úÖ Just use the output directly without indexing\n",
    "shap_values = explainer.shap_values(X_valid)\n",
    "\n",
    "# Make sure it's the right shape\n",
    "print(\"SHAP shape:\", shap_values.shape)  # should be (n_rows, n_features)\n",
    "\n",
    "# ‚úÖ Build DataFrame\n",
    "shap_df = pd.DataFrame(shap_values, columns=X_valid.columns)\n",
    "shap_df[\"loan_default_proba\"] = y_pred_proba\n",
    "shap_df[\"predicted_label\"] = y_pred_thresh\n",
    "shap_df[\"actual_label\"] = y_valid.values\n",
    "\n",
    "# ‚úÖ Save for Tableau\n",
    "shap_df.to_csv(\"../data/final/shap_values_tableau.csv\", index=False)\n",
    "print(\"‚úÖ SHAP values saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2e5ac9d-2630-416e-9cf4-fffc6ac4fead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SHAP long-format file saved!\n"
     ]
    }
   ],
   "source": [
    "# üîÑ Melt SHAP values from wide to long format\n",
    "shap_long = shap_df.melt(\n",
    "    id_vars=[\"loan_default_proba\", \"predicted_label\", \"actual_label\"],\n",
    "    var_name=\"feature\",\n",
    "    value_name=\"shap_value\"\n",
    ")\n",
    "\n",
    "# üíæ Save for Tableau\n",
    "shap_long.to_csv(\"../data/final/shap_values_long.csv\", index=False)\n",
    "print(\"‚úÖ SHAP long-format file saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eecb6c4a-1879-4688-b1bc-80eb5de8d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Create CSV with global feature importance for Tableau\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load SHAP values and feature matrix\n",
    "shap_df = pd.read_csv(\"../data/final/shap_values_tableau.csv\")\n",
    "\n",
    "# Drop prediction columns\n",
    "feature_cols = shap_df.drop(columns=[\"loan_default_proba\", \"predicted_label\"])\n",
    "\n",
    "# Compute mean absolute SHAP per feature\n",
    "global_importance = (\n",
    "    feature_cols.abs()\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"feature_name\", 0: \"mean_abs_shap_value\"})\n",
    "    .sort_values(\"mean_abs_shap_value\", ascending=False)\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "global_importance.to_csv(\"../data/final/global_shap_importance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10addc3a-24a9-4591-b35d-c6952267b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Prepare risk score data for Tableau visualization\n",
    "\n",
    "# 3. Combine into a DataFrame\n",
    "risk_df = pd.DataFrame({\n",
    "    \"loan_default_proba\": y_pred_proba,\n",
    "    \"true_label\": y_valid.values.flatten()\n",
    "})\n",
    "\n",
    "# 4. Optional: Create label names for Tableau (e.g., \"Default\", \"No Default\")\n",
    "risk_df[\"label\"] = risk_df[\"true_label\"].map({1: \"Default\", 0: \"No Default\"})\n",
    "\n",
    "# 5. Save to CSV\n",
    "risk_df.to_csv(\"../data/final/risk_distribution.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07e0203-42ab-48c2-9ed0-ac3c8692694a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Simplified risk_distribution.csv saved.\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Only include available columns\n",
    "available_cols = [\n",
    "    \"loan_default_proba\",\n",
    "    \"actual_label\",\n",
    "    \"DAYS_BIRTH\",\n",
    "    \"AMT_INCOME_TOTAL\",\n",
    "    \"DAYS_EMPLOYED\"\n",
    "]\n",
    "\n",
    "X_valid_final[\"label\"] = X_valid_final[\"actual_label\"].map({0: \"No Default\", 1: \"Default\"})\n",
    "risk_df = X_valid_final[available_cols + [\"label\"]]\n",
    "risk_df.to_csv(\"../data/final/risk_distribution.csv\", index=False)\n",
    "print(\"‚úÖ Simplified risk_distribution.csv saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67e64e1-1dab-4f5b-a798-a8e0bb2b2a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SHAP aggregation saved for Tableau!\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Load SHAP values + risk scores\n",
    "import pandas as pd\n",
    "shap_df = pd.read_csv(\"../data/final/shap_values_tableau.csv\")\n",
    "\n",
    "# üè∑Ô∏è Create risk bands from predicted probabilities\n",
    "bins = [0, 0.2, 0.5, 1.0]\n",
    "labels = [\"Low Risk\", \"Medium Risk\", \"High Risk\"]\n",
    "shap_df[\"risk_band\"] = pd.cut(shap_df[\"loan_default_proba\"], bins=bins, labels=labels)\n",
    "\n",
    "# üîù Top 15 features based on mean absolute SHAP value\n",
    "mean_abs_shap = shap_df.drop(columns=[\"loan_default_proba\", \"predicted_label\", \"risk_band\"]).abs().mean()\n",
    "top_features = mean_abs_shap.sort_values(ascending=False).head(15).index.tolist()\n",
    "\n",
    "# üìä Melt and group for Tableau\n",
    "shap_melted = shap_df[[\"risk_band\"] + top_features].melt(id_vars=\"risk_band\", var_name=\"feature\", value_name=\"shap_value\")\n",
    "agg_df = shap_melted.groupby([\"risk_band\", \"feature\"], observed=True).mean().reset_index()\n",
    "\n",
    "# üíæ Save for Tableau\n",
    "agg_df.to_csv(\"../data/final/agg_shap_by_risk_band.csv\", index=False)\n",
    "print(\"‚úÖ SHAP aggregation saved for Tableau!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f79f113-58b1-47ca-a3e5-c9ddd914b3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: shap_vs_risk_long.csv\n"
     ]
    }
   ],
   "source": [
    "# Purpose: Prepare SHAP vs Risk Score visualization data in long format for Tableau\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load the saved shap_vs_risk.csv\n",
    "df = pd.read_csv(\"../data/final/shap_vs_risk.csv\")\n",
    "\n",
    "# 2. Define correct column names\n",
    "feature_cols = [\n",
    "    \"EXT_SOURCE_1\",\n",
    "    \"EXT_SOURCE_2\",\n",
    "    \"EXT_SOURCE_3\",\n",
    "    \"credit_annuity_ratio\",\n",
    "    \"credit_goods_ratio\",\n",
    "    \"CODE_GENDER_M\",\n",
    "    \"DAYS_BIRTH\",\n",
    "    \"ORGANIZATION_TYPE_TE\"\n",
    "]\n",
    "\n",
    "# 3. Melt into long format\n",
    "long_df = df.melt(\n",
    "    id_vars=[\"loan_default_proba\"],\n",
    "    value_vars=feature_cols,\n",
    "    var_name=\"Feature\",\n",
    "    value_name=\"SHAP Value\"\n",
    ")\n",
    "\n",
    "# 4. Save to CSV for Tableau\n",
    "long_df.to_csv(\"../data/final/shap_vs_risk_long.csv\", index=False)\n",
    "print(\"‚úÖ Saved: shap_vs_risk_long.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f96467c5-def4-4988-bdb4-9a496b8f23c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: confusion_matrix_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Imports (in case not already)\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ‚úÖ Calculate confusion matrix components\n",
    "cm = confusion_matrix(X_valid_final[\"actual_label\"], X_valid_final[\"predicted_label\"])\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# üßæ Create a summary DataFrame\n",
    "confusion_summary = pd.DataFrame({\n",
    "    \"Metric\": [\"True Negative\", \"False Positive\", \"False Negative\", \"True Positive\"],\n",
    "    \"Count\": [tn, fp, fn, tp]\n",
    "})\n",
    "\n",
    "# üíæ Save the confusion matrix summary\n",
    "confusion_summary.to_csv(\"../data/final/confusion_matrix_summary.csv\", index=False)\n",
    "print(\"‚úÖ Saved: confusion_matrix_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07963872-0c6e-4a97-a8c3-a4b585ada2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: confusion_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# üßÆ Save row-level predictions\n",
    "X_valid_final[[\"loan_default_proba\", \"predicted_label\", \"actual_label\"]].to_csv(\n",
    "    \"../data/final/confusion_predictions.csv\", index=False\n",
    ")\n",
    "print(\"‚úÖ Saved: confusion_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "618c73dc-c638-4c28-946f-838a30d1626d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Combined file saved with consistent dtypes and no warnings.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your two CSVs\n",
    "summary_df = pd.read_csv(\"../data/final/confusion_matrix_summary.csv\")\n",
    "pred_df = pd.read_csv(\"../data/final/confusion_predictions.csv\")\n",
    "\n",
    "# Add missing columns with explicit types\n",
    "summary_df[\"loan_default_proba\"] = pd.Series([np.nan] * len(summary_df), dtype=\"float64\")\n",
    "summary_df[\"actual_label\"] = pd.Series([np.nan] * len(summary_df), dtype=\"float64\")\n",
    "summary_df[\"predicted_label\"] = pd.Series([np.nan] * len(summary_df), dtype=\"float64\")\n",
    "summary_df[\"Source\"] = \"Summary\"\n",
    "\n",
    "pred_df[\"Metric\"] = pd.Series([pd.NA] * len(pred_df), dtype=\"string\")\n",
    "pred_df[\"Count\"] = pd.Series([np.nan] * len(pred_df), dtype=\"float64\")\n",
    "pred_df[\"Source\"] = \"Prediction\"\n",
    "\n",
    "# Define consistent column order\n",
    "combined_cols = [\"Metric\", \"Count\", \"loan_default_proba\", \"actual_label\", \"predicted_label\", \"Source\"]\n",
    "\n",
    "# Reorder and ensure alignment\n",
    "summary_part = summary_df[combined_cols]\n",
    "pred_part = pred_df[combined_cols]\n",
    "\n",
    "# Concatenate without warning\n",
    "combined_df = pd.concat([summary_part, pred_part], ignore_index=True)\n",
    "\n",
    "# Save\n",
    "combined_df.to_csv(\"../data/final/confusion_combined.csv\", index=False)\n",
    "print(\"‚úÖ Combined file saved with consistent dtypes and no warnings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d542704-7186-4e7b-a7fa-610ca48c74a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Shape: (61507, 6)\n",
      "üßæ Column names: ['Metric', 'Count', 'loan_default_proba', 'actual_label', 'predicted_label', 'Source']\n",
      "üìå Sample rows:\n",
      "           Metric    Count  loan_default_proba  actual_label  predicted_label  \\\n",
      "0   True Negative  55095.0                 NaN           NaN              NaN   \n",
      "1  False Positive   1443.0                 NaN           NaN              NaN   \n",
      "2  False Negative   4122.0                 NaN           NaN              NaN   \n",
      "3   True Positive    843.0                 NaN           NaN              NaN   \n",
      "4             NaN      NaN            0.032648           0.0              0.0   \n",
      "5             NaN      NaN            0.060563           0.0              0.0   \n",
      "6             NaN      NaN            0.282761           0.0              0.0   \n",
      "7             NaN      NaN            0.076722           0.0              0.0   \n",
      "8             NaN      NaN            0.081543           0.0              0.0   \n",
      "9             NaN      NaN            0.078865           0.0              0.0   \n",
      "\n",
      "       Source  \n",
      "0     Summary  \n",
      "1     Summary  \n",
      "2     Summary  \n",
      "3     Summary  \n",
      "4  Prediction  \n",
      "5  Prediction  \n",
      "6  Prediction  \n",
      "7  Prediction  \n",
      "8  Prediction  \n",
      "9  Prediction  \n",
      "üéØ Unique values in Actual and Predicted Labels:\n",
      "  - Actual: [nan  0.  1.]\n",
      "  - Predicted: [nan  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/final/confusion_combined.csv\")\n",
    "\n",
    "print(\"üî¢ Shape:\", df.shape)\n",
    "print(\"üßæ Column names:\", df.columns.tolist())\n",
    "print(\"üìå Sample rows:\")\n",
    "print(df.head(10))\n",
    "print(\"üéØ Unique values in Actual and Predicted Labels:\")\n",
    "print(\"  - Actual:\", df[\"actual_label\"].unique())\n",
    "print(\"  - Predicted:\", df[\"predicted_label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a7ae8c2-d084-4f80-99c4-bcc469fed35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned file saved!\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/final/confusion_combined.csv\")\n",
    "\n",
    "# ‚úÖ Keep only the prediction rows\n",
    "df_pred = df[df[\"Source\"] == \"Prediction\"].copy()\n",
    "\n",
    "# ‚úÖ Save clean version for Tableau\n",
    "df_pred.to_csv(\"../data/final/confusion_prediction_only.csv\", index=False)\n",
    "print(\"‚úÖ Cleaned file saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95398efa-2f59-4ef8-864b-e451a671effe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Shape: (61503, 6)\n",
      "üßæ Column names: ['Metric', 'Count', 'loan_default_proba', 'actual_label', 'predicted_label', 'Source']\n",
      "üìå Sample rows:\n",
      "   Metric  Count  loan_default_proba  actual_label  predicted_label  \\\n",
      "0     NaN    NaN            0.032648           0.0              0.0   \n",
      "1     NaN    NaN            0.060563           0.0              0.0   \n",
      "2     NaN    NaN            0.282761           0.0              0.0   \n",
      "3     NaN    NaN            0.076722           0.0              0.0   \n",
      "4     NaN    NaN            0.081543           0.0              0.0   \n",
      "5     NaN    NaN            0.078865           0.0              0.0   \n",
      "6     NaN    NaN            0.004224           0.0              0.0   \n",
      "7     NaN    NaN            0.004712           0.0              0.0   \n",
      "8     NaN    NaN            0.402899           0.0              1.0   \n",
      "9     NaN    NaN            0.087414           1.0              0.0   \n",
      "\n",
      "       Source  \n",
      "0  Prediction  \n",
      "1  Prediction  \n",
      "2  Prediction  \n",
      "3  Prediction  \n",
      "4  Prediction  \n",
      "5  Prediction  \n",
      "6  Prediction  \n",
      "7  Prediction  \n",
      "8  Prediction  \n",
      "9  Prediction  \n",
      "üéØ Unique values in Actual and Predicted Labels:\n",
      "  - Actual: [0. 1.]\n",
      "  - Predicted: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/final/confusion_prediction_only.csv\")\n",
    "\n",
    "print(\"üî¢ Shape:\", df.shape)\n",
    "print(\"üßæ Column names:\", df.columns.tolist())\n",
    "print(\"üìå Sample rows:\")\n",
    "print(df.head(10))\n",
    "print(\"üéØ Unique values in Actual and Predicted Labels:\")\n",
    "print(\"  - Actual:\", df[\"actual_label\"].unique())\n",
    "print(\"  - Predicted:\", df[\"predicted_label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05410f4d-9b6b-49fd-bd05-52ae5eccc6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summary saved: confusion_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load predictions (assuming you already have these)\n",
    "# y_valid = ground truth labels\n",
    "# y_pred_thresh = predicted labels (0 or 1)\n",
    "\n",
    "# Define confusion matrix components\n",
    "TP = ((y_valid == 1) & (y_pred_thresh == 1)).sum()\n",
    "TN = ((y_valid == 0) & (y_pred_thresh == 0)).sum()\n",
    "FP = ((y_valid == 0) & (y_pred_thresh == 1)).sum()\n",
    "FN = ((y_valid == 1) & (y_pred_thresh == 0)).sum()\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_df = pd.DataFrame({\n",
    "    \"Metric\": [\"True Positive\", \"False Positive\", \"False Negative\", \"True Negative\"],\n",
    "    \"Count\": [TP, FP, FN, TN],\n",
    "    \"loan_default_proba\": [pd.NA] * 4,\n",
    "    \"actual_label\": [pd.NA] * 4,\n",
    "    \"predicted_label\": [pd.NA] * 4,\n",
    "    \"Source\": [\"Summary\"] * 4\n",
    "})\n",
    "\n",
    "# Save to CSV to be used in Tableau\n",
    "summary_df.to_csv(\"../data/final/confusion_summary.csv\", index=False)\n",
    "print(\"‚úÖ Summary saved: confusion_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf462ab-d458-45de-ae51-f0e2b112784d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
